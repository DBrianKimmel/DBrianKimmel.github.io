{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to My Documentation Site Augmented Living Development Documentation System Kubernetes (K3S) Docker Ansible Projects","title":"Home"},{"location":"#welcome-to-my-documentation-site","text":"Augmented Living Development Documentation System Kubernetes (K3S) Docker Ansible Projects","title":"Welcome to My Documentation Site"},{"location":"about/","text":"About","title":"About"},{"location":"about/#about","text":"","title":"About"},{"location":"license/","text":"License MIT License Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"license/#license","text":"","title":"License"},{"location":"license/#mit-license","text":"Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"MIT License"},{"location":"Ansible/","text":"Ansible Ansible is a neat way of automating the routine tasks of maintaining a number of computers. I started with ansible a few years ago but it got very complicated with two houses and a bunch of travel. Recently, we sold our summer home which greatly simplefies the location of the various computers. Also, I decided to set up a container system to keep things available and fault tolerant. Projects Auto Update","title":"Ansible"},{"location":"Ansible/#ansible","text":"Ansible is a neat way of automating the routine tasks of maintaining a number of computers. I started with ansible a few years ago but it got very complicated with two houses and a bunch of travel. Recently, we sold our summer home which greatly simplefies the location of the various computers. Also, I decided to set up a container system to keep things available and fault tolerant.","title":"Ansible"},{"location":"Ansible/#projects","text":"Auto Update","title":"Projects"},{"location":"Ansible/auto-update/","text":"Auto Update This will keep the computer (node) up to date with the system software (weekly). It will also keep the backups current (Monthly). ansible -b -m shell -a \"some command\"","title":"Auto Update"},{"location":"Ansible/auto-update/#auto-update","text":"This will keep the computer (node) up to date with the system software (weekly). It will also keep the backups current (Monthly). ansible -b -m shell -a \"some command\"","title":"Auto Update"},{"location":"Augmented_Living/","text":"Augmented Living In the USA and perhaps other places as well, Assisted Living is a place you go near the end of your life. So I use the term Augmented living to describe what a smart house helps you do. Instead of just automating the house, I believe the house should provide a lot more. Your house should know what it is that you want or need and provide it to you. You should not need to tell the house either by voice or changing the thermostat setting that it is too cold or too hot. If you like it cooler to sleep and you lie down in a bed somewhere in your house, that room should get or at least feel cooler. If you go into the bathroom at night while you are watching TV, the lights should illuminate your path and the bathroom. But, if you go the bathroom after being in bed, only the low illumination of night lights is needed.","title":"Augmented Living"},{"location":"Augmented_Living/#augmented-living","text":"In the USA and perhaps other places as well, Assisted Living is a place you go near the end of your life. So I use the term Augmented living to describe what a smart house helps you do. Instead of just automating the house, I believe the house should provide a lot more. Your house should know what it is that you want or need and provide it to you. You should not need to tell the house either by voice or changing the thermostat setting that it is too cold or too hot. If you like it cooler to sleep and you lie down in a bed somewhere in your house, that room should get or at least feel cooler. If you go into the bathroom at night while you are watching TV, the lights should illuminate your path and the bathroom. But, if you go the bathroom after being in bed, only the low illumination of night lights is needed.","title":"Augmented Living"},{"location":"Development/","text":"Development Howdy.","title":"Development"},{"location":"Development/#development","text":"Howdy.","title":"Development"},{"location":"Docker/","text":"Docker I have docker running in my Kubernetes HA Cluster. Here are the projects I have running as docker continers. MkDocs","title":"Docker"},{"location":"Docker/#docker","text":"I have docker running in my Kubernetes HA Cluster. Here are the projects I have running as docker continers. MkDocs","title":"Docker"},{"location":"Docker/MkDocs/","text":"MkDocs Docs Docker Image for AMD64 docker pull squidfunk/mkdocs-material Image for ARM64 and others docker pull ghcr.io/afritzler/mkdocs-material:latest run docker run --rm -it -v ${PWD}:/docs squidfunk/mkdocs-material new . docker run --rm -it -v ${PWD}:/docs ghcr.io/afritzler/mkdocs-material:latest .","title":"MkDocs"},{"location":"Docker/MkDocs/#mkdocs","text":"Docs","title":"MkDocs"},{"location":"Docker/MkDocs/#docker","text":"Image for AMD64 docker pull squidfunk/mkdocs-material Image for ARM64 and others docker pull ghcr.io/afritzler/mkdocs-material:latest","title":"Docker"},{"location":"Docker/MkDocs/#run","text":"docker run --rm -it -v ${PWD}:/docs squidfunk/mkdocs-material new . docker run --rm -it -v ${PWD}:/docs ghcr.io/afritzler/mkdocs-material:latest .","title":"run"},{"location":"Documentation/","text":"Documentation I came across a very neat dcumentation system named MkDocs. Here is how I set it up. Development Also, I created a GitHub Pages site for all this documentation. Git Hub","title":"Documentation"},{"location":"Documentation/#documentation","text":"I came across a very neat dcumentation system named MkDocs. Here is how I set it up. Development Also, I created a GitHub Pages site for all this documentation. Git Hub","title":"Documentation"},{"location":"Documentation/development/","text":"Development I have several development computers. Keeping them updated is a pain since they run different Linux distributions. Code editing I used to use emacs but also learned vi. Later on I discovered Eclipse and switched to using it. Now I have discovered Visual Studio Code and am switching to it. VS seems to be the most natural to me and has a lot of the things I use already integrated. It also seems more natural than Eclipse. MkDocs This documentation is created using MkDocs. The software is loaded on some of the development computers. Run the following to load the documentation software. pip install mkdocs pip install mkdocs-git-revision-date-plugin pip install mkdocs-material","title":"Development"},{"location":"Documentation/development/#development","text":"I have several development computers. Keeping them updated is a pain since they run different Linux distributions.","title":"Development"},{"location":"Documentation/development/#code-editing","text":"I used to use emacs but also learned vi. Later on I discovered Eclipse and switched to using it. Now I have discovered Visual Studio Code and am switching to it. VS seems to be the most natural to me and has a lot of the things I use already integrated. It also seems more natural than Eclipse.","title":"Code editing"},{"location":"Documentation/development/#mkdocs","text":"This documentation is created using MkDocs. The software is loaded on some of the development computers. Run the following to load the documentation software. pip install mkdocs pip install mkdocs-git-revision-date-plugin pip install mkdocs-material","title":"MkDocs"},{"location":"Kubernetes/","text":"K3S Kubernetes I have elected to build a Highly Available (HA) Kubernetes cluster using Rancher K3S. The build. The 1st control node 2nd and 3rd Control nodes First Worker node Other Worker Nodes","title":"K3S Kubernetes"},{"location":"Kubernetes/#k3s-kubernetes","text":"I have elected to build a Highly Available (HA) Kubernetes cluster using Rancher K3S. The build. The 1st control node 2nd and 3rd Control nodes First Worker node Other Worker Nodes","title":"K3S Kubernetes"},{"location":"Kubernetes/First-Control/","text":"First Control Node First we will pick out the computer we will use as the first control node. This node will have several other functions: - ansible installer for the cluster. - central log for the cluster. sudo apt install arp-scan Ansible Install Ansible sudo apt install ansible Next, we need to create a file /etc/ansible/hosts (or edit it), and add our hosts. In essence, here we define hosts and groups of hosts that Ansible will try to manage. Edit file /etc/ansible/hosts [control] control01 ansible_connection=local var_hostname=control01 control02 ansible_connection=ssh var_hostname=control02 control03 ansible_connection=ssh var_hostname=control03 [workers] cube01 ansible_connection=ssh var_hostname=cube01 cube02 ansible_connection=ssh var_hostname=cube02 cube03 ansible_connection=ssh var_hostname=cube03 cube04 ansible_connection=ssh var_hostname=cube04 cube05 ansible_connection=ssh var_hostname=cube05 cube06 ansible_connection=ssh var_hostname=cube06 [cube:children] control workers Master 1 In our case: pi-12-pp This is our primary node, one of 3 control nodes. We are going to install the K3s version. Use the following command to download and initialize K3s\u2019 master node. We pasted the --server into the command to tell it that we will be adding additional master nodes: If k3s has been installed: sudo k3s-killall.sh sudo k3s- curl -sfL https://get.k3s.io | K3S_TOKEN=\"some_random_password\" sh -s - server --cluster-init --disable servicelb","title":"First Control Node"},{"location":"Kubernetes/First-Control/#first-control-node","text":"First we will pick out the computer we will use as the first control node. This node will have several other functions: - ansible installer for the cluster. - central log for the cluster. sudo apt install arp-scan","title":"First Control Node"},{"location":"Kubernetes/First-Control/#ansible","text":"","title":"Ansible"},{"location":"Kubernetes/First-Control/#install-ansible","text":"sudo apt install ansible Next, we need to create a file /etc/ansible/hosts (or edit it), and add our hosts. In essence, here we define hosts and groups of hosts that Ansible will try to manage.","title":"Install Ansible"},{"location":"Kubernetes/First-Control/#edit-file-etcansiblehosts","text":"[control] control01 ansible_connection=local var_hostname=control01 control02 ansible_connection=ssh var_hostname=control02 control03 ansible_connection=ssh var_hostname=control03 [workers] cube01 ansible_connection=ssh var_hostname=cube01 cube02 ansible_connection=ssh var_hostname=cube02 cube03 ansible_connection=ssh var_hostname=cube03 cube04 ansible_connection=ssh var_hostname=cube04 cube05 ansible_connection=ssh var_hostname=cube05 cube06 ansible_connection=ssh var_hostname=cube06 [cube:children] control workers","title":"Edit file /etc/ansible/hosts"},{"location":"Kubernetes/First-Control/#master-1","text":"In our case: pi-12-pp This is our primary node, one of 3 control nodes. We are going to install the K3s version. Use the following command to download and initialize K3s\u2019 master node. We pasted the --server into the command to tell it that we will be adding additional master nodes: If k3s has been installed: sudo k3s-killall.sh sudo k3s- curl -sfL https://get.k3s.io | K3S_TOKEN=\"some_random_password\" sh -s - server --cluster-init --disable servicelb","title":"Master 1"},{"location":"Kubernetes/First-Worker/","text":"First Worker Node","title":"First Worker Node"},{"location":"Kubernetes/First-Worker/#first-worker-node","text":"","title":"First Worker Node"},{"location":"Kubernetes/Kubernetes/","text":"Building a Kubernetes HA cluster My goal is to have a Highly Available (HA) \"Smart\" home. To do that, I am building a Kubernetes cluster using Raspberry Pis. Controller Other Controllers","title":"Building a Kubernetes HA cluster"},{"location":"Kubernetes/Kubernetes/#building-a-kubernetes-ha-cluster","text":"My goal is to have a Highly Available (HA) \"Smart\" home. To do that, I am building a Kubernetes cluster using Raspberry Pis. Controller Other Controllers","title":"Building a Kubernetes HA cluster"},{"location":"Kubernetes/Other-Control/","text":"Additional Control Nodes","title":"Additional Control Nodes"},{"location":"Kubernetes/Other-Control/#additional-control-nodes","text":"","title":"Additional Control Nodes"},{"location":"Kubernetes/Other-Worker/","text":"Additional Worker Nodes","title":"Additional Worker Nodes"},{"location":"Kubernetes/Other-Worker/#additional-worker-nodes","text":"","title":"Additional Worker Nodes"},{"location":"Kubernetes/Features/","text":"Features Here are some various features that I have put into my Kubernetes HA Cluster. Central Logging {}","title":"Features"},{"location":"Kubernetes/Features/#features","text":"Here are some various features that I have put into my Kubernetes HA Cluster. Central Logging {}","title":"Features"},{"location":"Kubernetes/Features/CentralLogging/","text":"Central Logging Server Pick a server. I used pi-12-pp which is the first control node also. On Logging Server Create a place to hold all the logs. sudo mkdir /var/log/central sudo chown syslog:adm /var/log/central Rsyslog will use TCP/UDP port 514, but you need to enable it. Edit /etc/rsyslog.conf, and make sure these lines look like this (by uncommenting them): sudo nano /etc/rsyslog.conf # provides UDP syslog reception module(load=\"imudp\") input(type=\"imudp\" port=\"514\") # provides TCP syslog reception module(load=\"imtcp\") input(type=\"imtcp\" port=\"514\") Next create config to tell rsyslog to put all logs in previously created folder, create /etc/rsyslog.d/45-central.conf sudo nano /etc/rsyslog.d/45-central.conf $template RemoteLogs,\"/var/log/central/%HOSTNAME%.log\" *.* ?RemoteLogs This will put all logs under /var/log/central/ .log Last thing, and this is kind of optional, we need to tell logrotate about this, and have it rotate the logs, so you don't end up with 100+MB text files. Create file /etc/logrotate.d/central /var/log/central/*.log { rotate 4 weekly missingok notifempty compress delaycompress sharedscripts postrotate invoke-rc.d rsyslog rotate >/dev/null 2>&1 || true endscript } rotate - How many rotated copies to keep before removing the oldest one. weekly - Rotate log every 7 days. missingok - If the log file is missing, go on to the next one without issuing an error message. notifempty - Do not rotate the log if it is empty. compress - Gzip the logs. delaycompress - Postpone compression of the previous log file to the next rotation cycle. sharedscripts - Because we are going to use wildcard, we need this argument, telling logrotate this setting is for multiple logs. postrotate - What to do after rotation is finished, in this case invoke rsyslog rotate. Some more info about options: https://linux.die.net/man/8/logrotate Restart rsyslog sudo systemctl restart rsyslog That\u2019s it for a server, no need to restart logrotate; that will be run via cron. lnav Just a nifty little program to watch your logs in real time, with filters and so on. sudo apt install lnav lnav /var/log/central/*.log","title":"Central Logging"},{"location":"Kubernetes/Features/CentralLogging/#central-logging","text":"","title":"Central Logging"},{"location":"Kubernetes/Features/CentralLogging/#server","text":"Pick a server. I used pi-12-pp which is the first control node also.","title":"Server"},{"location":"Kubernetes/Features/CentralLogging/#on-logging-server","text":"Create a place to hold all the logs. sudo mkdir /var/log/central sudo chown syslog:adm /var/log/central Rsyslog will use TCP/UDP port 514, but you need to enable it. Edit /etc/rsyslog.conf, and make sure these lines look like this (by uncommenting them): sudo nano /etc/rsyslog.conf # provides UDP syslog reception module(load=\"imudp\") input(type=\"imudp\" port=\"514\") # provides TCP syslog reception module(load=\"imtcp\") input(type=\"imtcp\" port=\"514\") Next create config to tell rsyslog to put all logs in previously created folder, create /etc/rsyslog.d/45-central.conf sudo nano /etc/rsyslog.d/45-central.conf $template RemoteLogs,\"/var/log/central/%HOSTNAME%.log\" *.* ?RemoteLogs This will put all logs under /var/log/central/ .log Last thing, and this is kind of optional, we need to tell logrotate about this, and have it rotate the logs, so you don't end up with 100+MB text files. Create file /etc/logrotate.d/central /var/log/central/*.log { rotate 4 weekly missingok notifempty compress delaycompress sharedscripts postrotate invoke-rc.d rsyslog rotate >/dev/null 2>&1 || true endscript } rotate - How many rotated copies to keep before removing the oldest one. weekly - Rotate log every 7 days. missingok - If the log file is missing, go on to the next one without issuing an error message. notifempty - Do not rotate the log if it is empty. compress - Gzip the logs. delaycompress - Postpone compression of the previous log file to the next rotation cycle. sharedscripts - Because we are going to use wildcard, we need this argument, telling logrotate this setting is for multiple logs. postrotate - What to do after rotation is finished, in this case invoke rsyslog rotate. Some more info about options: https://linux.die.net/man/8/logrotate Restart rsyslog sudo systemctl restart rsyslog That\u2019s it for a server, no need to restart logrotate; that will be run via cron.","title":"On Logging Server"},{"location":"Kubernetes/Features/CentralLogging/#lnav","text":"Just a nifty little program to watch your logs in real time, with filters and so on. sudo apt install lnav lnav /var/log/central/*.log","title":"lnav"},{"location":"Projects/","text":"Projects PiHole DNS MkDocs","title":"Projects"},{"location":"Projects/#projects","text":"PiHole DNS MkDocs","title":"Projects"}]}